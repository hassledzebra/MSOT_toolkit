
# MSOT Analysis Pipeline

This is an analytical pipeline for the iThera MSOT InVision 256-TF imaging 
system. Using the computational flexibility of MATLAB, users can create a straightforward

## Pipeline Structure

The pipeline provides a variety of functions and exit points, as well as configuration details.

It is generally assumed that the user will configure their pipelines through a combination of defaults and parameters specified on a per-pipeline basis, and 
will use the driver interface in order to process their data. When invoking the pipeline, it is assumed that an input folder is available, containing the files associated with an MSOT scan (e.g. Scan_1.msot, Scan_1.bin, Scan_1.nod). The input folder should also contain a file ``params.json``, in JSON format, which specifies parameters to use for a given pipeline. 

Before running the pipeline, make sure that the folder containing this README is added to your MATLAB path.

When running the pipeline, the invocation is specified as ``driver(<step>,<input_folder>,<output_folder>)``. If ``<output_folder>`` is not provided, it is assumed to be the same as the input folder. It is generally preferred to run all of the steps in the same folder - otherwise you will need to copy the data from each output folder to the next input folder. This enables the usage of Nextflow, which manages this copy operation for you. 

``<step>`` can be one of 5 steps, presented below in the order they are expected to be used:
 - ``drivePreprocessing``, which will generate the ``pipelineMeta.mat`` file required to run the rest of the pipeline. This file contains all of the details which determine how the pipeline executes, including the model used, reconstruction method, wavelengths used, etc. 
 - ``driveRecons``, which will run the reconstructions either locally or in parallel. If run in parallel, this will generate many separate reconstructions, 1 for each chunk of the reconstructions taken by each worker.
 - ``collatePipelineOutput``, which will consolidate the reconstructions generated by ``driveRecons`` into a single monolithic reconstruction.
 - ``driveUnmixing`` will take the reconstructions and perform unmixing on them, generating a mat and meta file.
 - ``driveHDF5Writing`` will take the reconstructions and unmixed files in the input files and output the same data in HDF5 format files suitable for opening in HDFView or in ImageJ.

The file examplePipeline.m demonstrates the manual usage of a pipeline, including the loading of endmembers and direct unmixing with export of both reconstructed image frames
as well as unmixed image frames. Note that spectra must be imported before an unmixing routine can be used.

The file ./+util/defaults.m contains a series of default configurations which are loaded during pipelinePreprocessing. 

Spectra should be kept in a folder ./external/spectra and in a two-column format where the first column is the wavelength in nanometers and the second is the molar extinction coefficient for that compound's spectrum. The file should be named ``<compound>Spectrum.mat``, though csv files may also be used for convenience.
## This Package

This workflow package is composed of several modules:

  1) The pre-filters, which operate on both the signal and dataset levels. The
  signal pre-filters allow for the definition of high- and low-pass filters, as
  well as providing various options for removing the impulse response function 
  from the signal. 
  
  2) Reconstruction systems, which takes pre-filtered data and the configuration
  file and performs an image reconstruction on the filtered dataset. Various 
  methods can be used, including backprojection and model-based reconstructions,
  as well as various regularizers and constraints applied to the reconstruction
  process.
  
  3) The multispectral processing, which takes a set of input spectra and 
  attempts to unmix the given photoacoustic signal into relative concentrations
  of its constituent endmembers. 
    

  Loaders: Fetch MSOT signals, which will have two fields: data and meta.
  Prefilter: Takes in a signal and outputs a signal of the same size and sense.
  ReconSystem: Takes in a Model and a Solver on construction, or configurations to define same, and applies that system to 
  the data which is received from the prefilter.
  Writers: Output MSOT signals to some target location. Formatting is agnostic; it just has to 
  be able to take a data array and a meta structure during operation.

## MATLAB Toolbox
  The MATLAB component of the pipeline is intended to be usable in a standalone fashion, independently from Nextflow.
  
  The interface with the acquired data is done via an object-oriented memory map approach, in order to avoid loading massive
  datasets into memory. 

  Prior to use, the base folder (the one at ./workflow/scripts/ containing `example.m`) should be added to the MATLAB path in order to give scope access to the packages.

  In first using the loading tools, the user either creates an `msotData` object by calling `util.msotData(<filename>)` or creates a loader directly by 
  calling `util.MSOTSignalLoader(<filename>)`. The `msotData` object is a MATLAB handle class, and so is copied by reference, not by value. Before 
  accessing the metadata, it should be initialized via a call to the `calculateStructure` method. 

  The Loader, once initialized, acts on a binary file to yield individual data frames, which consist of a data component and a meta component associated with some sensible chunk of data. 
  For the InVision 256-TF, this is the data associated with a single shot of the laser hardware. The data component is the 'meat' of the frame, 
  and is usually a numerical array. The meta component is all information associated with the frame, and contains such information as the laser 
  energy readout or water bath temperature. 

  The PreFilter conditions the raw data frames. This consists of a Wiener deconvolution step in order to remove the impulse response function (IRF) of the data, followed by a bandpass filter to remove high- and low-frequency noise which may reduce the quality of the reconstruction or cause divergence of the solution.

  The ReconSystem converts a data frame into a reconstructed image according to specified user settings. 



























# Testing/Running the Workflow with the Astrocyte CLI

**Work in Progress - CLI not yet available on the cluster**

Workflows will usually be run from the Astrocyte web interface, by importing the
workflow package repository and making it available to users. During development
You can use the Astrocyte CLI scripts to check, test, and run your workflow
against non-test data.

First load the `astrocyte` module on a biohpc system.

To check the structure and syntax of the workflow package in the directory
`astrocyte_example_chipseq`:

```bash
$ astrocyte_cli check astrocyte_example_chipseq
```

To launch the workflows defined tests, against included test data:

```bash
$ astrocyte_cli test astrocyte_example_chipseq
```

To run the workflow using specific data and parameters. A working directory will
be created.

```bash
$ astrocyte_cli run astrocyte_example_chipseq --parameter1 "value1" --parameter2 "value2"...
```

To run the Shiny vizualization app against test_data

```bash
$ astrocyte_cli shinytest astrocyte_example_chipseq
```

To run the Shiny vizualization app against output from `astrocyte_cli run`,
which will be in the work directory created by `run`:

```bash
$ astrocyte_cli shiny astrocyte_example_chipseq
```

To generate the user-facing documentation for the workflow and display it in a
web browser:

```bash
$ astrocyte_cli docs astrocyte_example_chipseq
```